{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "92ff6000",
   "metadata": {},
   "source": [
    "![AutoGluon Logo](https://auto.gluon.ai/stable/_static/AutogluonLogo.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc67d0e5",
   "metadata": {},
   "source": [
    "# <a name=\"0\">AutoGluon Tutorial - TABULAR DATA</a>\n",
    "   \n",
    "This notebook demonstrates the simplest way to use AutoGluon for Tabular data. \n",
    "\n",
    "AutoGluon automates several tasks related to ML model development and builds highly accurate models. In this tutorial, you will test AutoGluon on a dataset comprising of demographics data about people. The goal is to identify whether or not a person’s yearly income exceeds $50,000.\n",
    "    \n",
    "> This is a __binary classification__ task. The label column indicates whether a person earns more than 50K a year or not.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca98799c",
   "metadata": {},
   "source": [
    "Let's solve the binary classification problem using __AutoGluon__.\n",
    "\n",
    "### Basic AutoGluon Features\n",
    "\n",
    "- <a href=\"#Importing-AutoGluon\">Importing AutoGluon </a>\n",
    "- <a href=\"#Getting-the-Data\">Getting the Data</a>\n",
    "- <a href=\"#Model-Training-with-AutoGluon\">Model Training with AutoGluon</a>\n",
    "- <a href=\"#AutoGluon-Training-Results\">AutoGluon Training Results</a>\n",
    "- <a href=\"#Model-Prediction\">Model Prediction with AutoGluon</a>\n",
    "\n",
    "### Advanced AutoGluon Features\n",
    "\n",
    "- <a href=\"#Specifying-performance-metric-and-Hyperparameter-Options\">Specifying performance metric and Hyperparameter Options </a>\n",
    "- <a href=\"#Model-ensembling-with-stacking-bagging\">Model ensembling with stacking/bagging</a>\n",
    "- <a href=\"#Prediction-options-inference\">Prediction options (inference)</a>\n",
    "- <a href=\"#Selecting-individual-models-predictions\">Selecting individual models for predictions</a>\n",
    "- <a href=\"#Interpretability-feature-importance\">Interpretability: Feature importance</a>\n",
    "- <a href=\"#Inference-speed-model-distillation\">Inference Speed: Model distillation</a>\n",
    "\n",
    "\n",
    "(<a href=\"#0\">Go to top</a>)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72279f58",
   "metadata": {},
   "source": [
    "Let's start by loading some libraries and packages."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a92e7c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip3 install -U -q pip\n",
    "!pip3 install -U -q setuptools wheel\n",
    "\n",
    "# CPU version of pytorch has smaller footprint - see installation instructions in\n",
    "# pytorch documentation - https://pytorch.org/get-started/locally/\n",
    "!pip3 install -q torch==1.12+cpu torchvision==0.13.0+cpu torchtext==0.13.0 -f https://download.pytorch.org/whl/cpu/torch_stable.html\n",
    "\n",
    "# Install the proper version of PyTorch following https://pytorch.org/get-started/locally/\n",
    "# UNCOMMENT THIS IF RUNNING WITH GPU\n",
    "#!pip3 install -q torch==1.12.0+cu113 torchvision==0.13.0+cu113 torchtext==0.13.0 --extra-index-url https://download.pytorch.org/whl/cu113\n",
    "\n",
    "!pip3 install -q autogluon"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d549f2e5",
   "metadata": {},
   "source": [
    "### <a id=\"Importing-AutoGluon\">Importing AutoGluon</a>\n",
    "\n",
    "We load the objects needed to work with our Tabular dataset, as well as the pandas library.\n",
    "\n",
    "(<a href=\"#0\">Go to top</a>)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "560e8f9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Importing objects from the newly installed AutoGluon code library\n",
    "from autogluon.tabular import TabularPredictor, TabularDataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ea7d2ea",
   "metadata": {},
   "source": [
    "### <a id=\"Getting-the-Data\">Getting the Data</a>\n",
    "\n",
    "Let's get the data for our binary classification problem and inspect it.\n",
    "\n",
    "Note that we load data from a CSV file stored in the cloud (AWS s3 bucket), but you can also specify a local file path.\n",
    "\n",
    "(<a href=\"#0\">Go to top</a>)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e92cf029",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the training dataset\n",
    "# Note that the TabularDataset can read files from local paths or from external URLs.\n",
    "df_train = TabularDataset(\"https://autogluon.s3.amazonaws.com/datasets/Inc/train.csv\")\n",
    "\n",
    "# Load the test dataset\n",
    "df_test = TabularDataset(\"https://autogluon.s3.amazonaws.com/datasets/Inc/test.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1c18ba4",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Number of data points: {len(df_train)}\")\n",
    "print(f\"Number of columns per data point: {len(df_train.columns)}\")\n",
    "\n",
    "df_train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41a2168c",
   "metadata": {},
   "source": [
    "We can see that the data file contains a series of demographics features for a number of people; let’s use them to predict whether each person’s income exceeds $50,000 or not, which is recorded in the `class` column of this table."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f74fb6a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Summary of class variable: \\n\", df_train[\"class\"].describe())\n",
    "print()\n",
    "df_train[\"class\"].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64440bdf",
   "metadata": {},
   "source": [
    "### <a id=\"Model-Training-with-AutoGluon\">Model Training with AutoGluon</a>\n",
    "\n",
    "We can train a model using AutoGluon with only a single line of code.  All we need to do is to tell it which column from the dataset we are trying to predict, and what the dataset is.\n",
    "\n",
    "__Optional:__ You may set a __time limit__ for AutoGluon to perform all the tasks related to ML model development. More time allows AutoGluon to try out more techniques to improve performance.\n",
    "\n",
    "(<a href=\"#0\">Go to top</a>)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "feb2e569",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Train a model with AutoGluon on the train dataset\n",
    "\n",
    "# Set the path to save models\n",
    "save_path = \"AutogluonModels/Tabular_Basic/\"\n",
    "\n",
    "# Subsample subset of data for faster demo, try setting this to much larger values\n",
    "subsample_size = 1000\n",
    "df_train_small = df_train.sample(n=subsample_size, random_state=42)\n",
    "\n",
    "# Set the training time to 5 minutes here, to achieve a quick result\n",
    "predictor = TabularPredictor(label=\"class\", path=save_path).fit(\n",
    "    train_data=df_train_small, time_limit=2 * 60\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7253fe12",
   "metadata": {},
   "source": [
    "### <a id=\"AutoGluon-Training-Results\">AutoGluon Results</a>\n",
    "Now let's take a look at all the information AutoGluon provides via its __leaderboard function__, which provides a summary of all models that AutoGluon trained. <br/> \n",
    "\n",
    "(<a href=\"#0\">Go to top</a>)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "444208f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictor.leaderboard(silent=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bfb3ac26",
   "metadata": {},
   "source": [
    "### <a id=\"Model-Prediction\">Model Prediction with AutoGluon</a>\n",
    "\n",
    "#### Now that your model is trained, let's use it to make predictions!\n",
    "\n",
    "We should always run a final model performance assessment using data that was unseen by the model (the test data). Test data is not used during training and can therefore give an unbiased performance assessment. \n",
    "\n",
    "(<a href=\"#0\">Go to top</a>)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77556e7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Inspect the test data\n",
    "df_test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "136e1e41",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get predictions\n",
    "predictions = predictor.predict(df_test)\n",
    "predictions.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fef8680b",
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluation = predictor.evaluate_predictions(\n",
    "    y_true=df_test[\"class\"], y_pred=predictions, auxiliary_metrics=True\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed94e8bb",
   "metadata": {},
   "source": [
    "Use `fit_summary()` to output a summary of information about models produced during `fit()`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b87b396",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "print(predictor.fit_summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8851343",
   "metadata": {},
   "source": [
    "<a id='ex'></a>\n",
    "### <mark>Your Turn: Improve the performance of your binary classifier using only basic AutoGluon options\n",
    "\n",
    "- Try training with more data points\n",
    "- Try training for a longer time\n",
    "    \n",
    "You can code your answer in the cell below. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5037020",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write your code here:\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b2dea74",
   "metadata": {},
   "source": [
    "---\n",
    "# <a id=\"Advanced AutoGluon Options\">Advanced AutoGluon Options</a>\n",
    "\n",
    "Now that you know how to use the `TabularPredictor` using 3 lines of code, let us try to understand some of the processes and available configurations AutoGluon offers.\n",
    "\n",
    "(<a href=\"#0\">Go to top</a>)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a72fa19d",
   "metadata": {},
   "source": [
    "## <a id=\"Specifying-performance-metric-and-Hyperparameter-Options\">Specifying performance metric and Hyperparameter Options</a>\n",
    "\n",
    "### Specifying performance metric\n",
    "AutoGluon automatically infers the performance metric to optimize given the type of problem. However, it is possible to explicitly specify the evaluation metric as well. \n",
    "The full list of AutoGluon classification metrics can be found here:\n",
    "\n",
    "`'accuracy', 'balanced_accuracy', 'f1', 'f1_macro', 'f1_micro', 'f1_weighted', 'roc_auc', 'average_precision', 'precision', 'precision_macro', 'precision_micro', 'precision_weighted', 'recall', 'recall_macro', 'recall_micro', 'recall_weighted', 'log_loss', 'pac_score'`\n",
    "\n",
    "(<a href=\"#0\">Go to top</a>)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "434436c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We can specify a different metric for optimization\n",
    "metric = \"f1\"\n",
    "\n",
    "# Train various models for ~30 min\n",
    "time_limit = 30 * 60"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5eeeb0f",
   "metadata": {},
   "source": [
    "### Hyperparameter Tuning\n",
    "\n",
    "Hyperparameter optimization improves model performance by finding the best combination of hyperparameter values. The choice of models and hyperparameters can be specified while calling the `fit()` method.\n",
    "\n",
    "You can specify various hyperparameter values for each type of model. For each hyperparameter, you can either specify a single fixed value, or a search space of values to consider during hyperparameter optimization. Hyperparameters which you do not specify are left at default settings chosen automatically by AutoGluon, which may be fixed values or search spaces.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "375ef5ac",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import autogluon.core as ag\n",
    "\n",
    "save_path = \"AutogluonModels/Tabular_Tuning/\"\n",
    "\n",
    "# Specifies non-default hyperparameter values for neural network models\n",
    "nn_options = {\n",
    "    \"num_epochs\": 10,  # number of training epochs (controls training time of NN models)\n",
    "    \"learning_rate\": ag.space.Real(\n",
    "        1e-4, 1e-2, default=5e-4, log=True\n",
    "    ),  # learning rate used in training (real-valued hyperparameter searched on log-scale)\n",
    "    \"activation\": ag.space.Categorical(\n",
    "        \"relu\", \"sigmoid\"\n",
    "    ),  # activation function used in NN (categorical hyperparameter, default = first entry)\n",
    "    \"dropout_prob\": ag.space.Real(\n",
    "        0.0, 0.4, default=0.1\n",
    "    ),  # dropout probability (real-valued hyperparameter)\n",
    "}\n",
    "\n",
    "# Specifies non-default hyperparameter values for lightGBM gradient boosted trees\n",
    "gbm_options = {\n",
    "    \"num_boost_round\": 100,  # number of boosting rounds (controls training time of GBM models)\n",
    "    \"num_leaves\": ag.space.Int(\n",
    "        lower=26, upper=66, default=36\n",
    "    ),  # number of leaves in trees (integer hyperparameter)\n",
    "}\n",
    "\n",
    "# Hyperparameters of each model type\n",
    "# When these keys are missing from hyperparameters dict, no models of that type are trained\n",
    "hyperparameters = {\n",
    "    \"GBM\": gbm_options,\n",
    "    \"NN_TORCH\": nn_options,  # NOTE: comment this line out if you get errors on Mac OSX\n",
    "}\n",
    "\n",
    "num_trials = (\n",
    "    5  # try at most 5 different hyperparameter configurations for each type of model\n",
    ")\n",
    "search_strategy = (\n",
    "    \"auto\"  # to tune hyperparameters using random search routine with a local scheduler\n",
    ")\n",
    "\n",
    "# HPO is not performed unless hyperparameter_tune_kwargs is specified\n",
    "hyperparameter_tune_kwargs = {\n",
    "    \"num_trials\": num_trials,\n",
    "    \"scheduler\": \"local\",\n",
    "    \"searcher\": search_strategy,\n",
    "}\n",
    "\n",
    "predictor_hpo = TabularPredictor(label=\"class\", path=save_path, eval_metric=metric).fit(\n",
    "    df_train,\n",
    "    time_limit=time_limit,\n",
    "    hyperparameters=hyperparameters,\n",
    "    hyperparameter_tune_kwargs=hyperparameter_tune_kwargs,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4fa65e3d",
   "metadata": {},
   "source": [
    "<a id='ex'></a>\n",
    "### <mark>Your Turn: Compute predictions for the HPO predictor and evaluate its performance.\n",
    "\n",
    "- Use `predict` on the test data set\n",
    "- Use `evaluate_predictions` and compare the performance with your previous results\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7179ea9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write your code here\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66802275",
   "metadata": {},
   "source": [
    "## <a name=\"Model-ensembling-with-stacking-bagging\">Model ensembling with stacking/bagging</a>\n",
    "(<a href=\"#0\">Go to top</a>)\n",
    "\n",
    "Beyond hyperparameter-tuning with a correctly-specified evaluation metric, there are two other methods to boost predictive performance:\n",
    "- bagging and \n",
    "- stack-ensembling\n",
    "\n",
    "You’ll often see performance improve if you specify `num_bag_folds = 5-10`, `num_stack_levels = 1-3` in the call to `fit()`. Beware that doing this will increase training times and memory/disk usage.\n",
    "\n",
    "You should not provide `tuning_data` when stacking/bagging, and instead provide all your available data as train_data (which AutoGluon will split in more intelligent ways). Parameter `num_bag_sets` controls how many times the K-fold bagging process is repeated to further reduce variance (increasing this may further boost accuracy but will substantially increase training times, inference latency, and memory/disk usage). Rather than manually searching for good bagging/stacking values yourself, AutoGluon will automatically select good values for you if you specify `auto_stack` instead:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8bf07434",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "save_path = \"AutogluonModels/Tabular_Stack/\"\n",
    "predictor_stack = TabularPredictor(label=\"class\", path=save_path, eval_metric=metric).fit(\n",
    "    train_data=df_train, auto_stack=True, time_limit=2 * 60\n",
    ")\n",
    "predictions_stack = predictor_stack.predict(df_test)\n",
    "evaluation_stack = predictor_stack.evaluate_predictions(\n",
    "    y_true=df_test[\"class\"], y_pred=predictions_large, auxiliary_metrics=True\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0bd28ebe",
   "metadata": {},
   "source": [
    "Often stacking/bagging will produce superior accuracy than hyperparameter-tuning, but you may try combining both techniques (note: specifying `presets='best_quality'` in `fit()` simply sets `auto_stack=True`)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3631cec3",
   "metadata": {},
   "source": [
    "---\n",
    "## <a name=\"Prediction-options-inference\">Prediction options (inference)</a>\n",
    "(<a href=\"#0\">Go to top</a>)\n",
    "\n",
    "Even if you’ve started a new Python session since last calling `fit()`, you can still load a previously trained predictor from disk:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e13bc8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "save_path = \"AutogluonModels/Tabular_Tuning/\"\n",
    "\n",
    "predictor = TabularPredictor.load(save_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12a77c1b",
   "metadata": {},
   "source": [
    "Above `save_path` is the same folder previously passed to `TabularPredictor`, in which the trained models have been saved. You can train easily models on one machine and deploy them on another. Simply copy the `save_path` folder to the new machine and specify its new path in `TabularPredictor.load()`.\n",
    "\n",
    "We can make a prediction on an individual example rather than on a full dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "884eea24",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select one datapoint to make a prediction\n",
    "datapoint = df_test.iloc[[0]] # Note: .iloc[0] won't work because it returns pandas Series instead of DataFrame\n",
    "\n",
    "predictor.predict(datapoint)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20635484",
   "metadata": {},
   "source": [
    "To output predicted class probabilities instead of predicted classes, you can use `predict_proba`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0801317d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Returns a DataFrame that shows which probability corresponds to which class\n",
    "predictor.predict_proba(datapoint)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4229a926",
   "metadata": {},
   "source": [
    "By default, `predict()` and `predict_proba()` will utilize the model that AutoGluon thinks is most accurate, which is usually an ensemble of many individual models. Here’s how to see which model this corresponds to:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67e87508",
   "metadata": {},
   "source": [
    "---\n",
    "## <a name=\"Selecting-individual-models-predictions\">Selecting individual models for predictions</a>\n",
    "(<a href=\"#0\">Go to top</a>)\n",
    "\n",
    "We can specify a particular model to use for predictions (e.g. to reduce inference latency). Note that a ‘model’ in AutoGluon may refer, for instance, to a single Neural Network, a bagged ensemble of many Neural Network copies trained on different training/validation splits, a weighted ensemble that aggregates the predictions of many other models, or a stacked model that operates on predictions output by other models. This is akin to viewing a RandomForest as one ‘model’ when it is in fact an ensemble of many decision trees.\n",
    "\n",
    "Here’s how to list all models trained by AutoGluon for a given predictor:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94d5c007",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictor.get_model_names()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ece7991",
   "metadata": {},
   "source": [
    "To use a particular model for prediction instead of AutoGluon’s default model-choice, we need to pass the model name as argument to the method `predict`: \n",
    "\n",
    "`predictor.predict(datapoint, model=<name_of_model_to_use>)`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3b74e88",
   "metadata": {},
   "source": [
    "<a id='ex'></a>\n",
    "### <mark>Your Turn: Compute predictions for your loaded predictor using a more performant trained model\n",
    "\n",
    "- Use `leaderboard` and `quantile` to find the model with the fastest inference speed among those with prediction time faster than the 80th percentile \n",
    "- Call `predict` using that model on the test data\n",
    "- Use `evaluate` to compute the performance of said model. Compare with AutoGluon's \"best\" model\n",
    "- Use `%timeit` to compare the speed of the performant model with AutoGluon's default"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3bf2589a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write your code here:\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "edd4664d",
   "metadata": {},
   "source": [
    "---\n",
    "## <a name=\"Interpretability-feature-importance\">Interpretability: Feature importance</a>\n",
    "(<a href=\"#0\">Go to top</a>)\n",
    "\n",
    "To better understand our trained predictor, we can estimate the overall importance of each feature:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ac4372b",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictor.feature_importance(df_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b45724ee",
   "metadata": {},
   "source": [
    "Computed via permutation-shuffling, these feature importance scores quantify the drop in predictive performance (of the already trained predictor) when one columns values are randomly shuffled across rows. The top features in this list contribute most to AutoGluon’s accuracy. Features with non-positive importance score hardly contribute to the predictors accuracy, or may even be actively harmful to include in the data (consider removing these features from your data and calling `fit` again). These scores facilitate interpretability of the predictors global behavior (which features it relies on for all predictions) rather than local explanations that only rationalize one particular prediction.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed5c0874",
   "metadata": {},
   "source": [
    "---\n",
    "## <a name=\"Inference-speed-model-distillation\">Inference Speed: Model distillation</a>\n",
    "(<a href=\"#0\">Go to top</a>)\n",
    "\n",
    "While computationally-favorable, single individual models will usually have lower accuracy than weighted/stacked/bagged ensembles. Model Distillation offers one way to retain the computational benefits of a single model, while enjoying some of the accuracy-boost that comes with ensembling. The idea is to train the individual model (which we can call the student) to mimic the predictions of the full stack ensemble (the teacher). Like `refit_full()`, the `distill()` function will produce additional models we can opt to use for prediction."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f291fee",
   "metadata": {},
   "source": [
    "### Training student models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7fea6b8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Specify much longer time limit in real applications\n",
    "student_models = predictor.distill(time_limit=2*60)\n",
    "student_models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09863002",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictor.leaderboard(silent=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ddb3347",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
